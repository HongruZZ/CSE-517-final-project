{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0fd619c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bddc169",
   "metadata": {},
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "eddf5c32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_rate</th>\n",
       "      <th>track</th>\n",
       "      <th>m</th>\n",
       "      <th>n</th>\n",
       "      <th>current_pitch</th>\n",
       "      <th>current_roll</th>\n",
       "      <th>absoluate_roll</th>\n",
       "      <th>climb_delta</th>\n",
       "      <th>roll_rate_delta</th>\n",
       "      <th>climb_delta_diff</th>\n",
       "      <th>...</th>\n",
       "      <th>time8_delta</th>\n",
       "      <th>time9_delta</th>\n",
       "      <th>time10_delta</th>\n",
       "      <th>time11_delta</th>\n",
       "      <th>time12_delta</th>\n",
       "      <th>time13_delta</th>\n",
       "      <th>time14_delta</th>\n",
       "      <th>omega</th>\n",
       "      <th>set</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-31</td>\n",
       "      <td>22</td>\n",
       "      <td>1.127497</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.44</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>-9</td>\n",
       "      <td>6</td>\n",
       "      <td>0.011</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>0.336472</td>\n",
       "      <td>0.050</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>185</td>\n",
       "      <td>-40</td>\n",
       "      <td>1.363425</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>0.30</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>-12</td>\n",
       "      <td>16</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>170</td>\n",
       "      <td>-17</td>\n",
       "      <td>0.794534</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-6</td>\n",
       "      <td>9</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-399</td>\n",
       "      <td>-8</td>\n",
       "      <td>0.697676</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>0.80</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>-7</td>\n",
       "      <td>15</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-24</td>\n",
       "      <td>-18</td>\n",
       "      <td>1.127497</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.85</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>-18</td>\n",
       "      <td>-3</td>\n",
       "      <td>0.019</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-0.223144</td>\n",
       "      <td>0.030</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8245</th>\n",
       "      <td>56</td>\n",
       "      <td>-40</td>\n",
       "      <td>0.886920</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>0.39</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-6</td>\n",
       "      <td>32</td>\n",
       "      <td>0.012</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8246</th>\n",
       "      <td>199</td>\n",
       "      <td>-35</td>\n",
       "      <td>1.185305</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1.5</td>\n",
       "      <td>-5</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8247</th>\n",
       "      <td>359</td>\n",
       "      <td>-3</td>\n",
       "      <td>0.852144</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.31</td>\n",
       "      <td>1.4</td>\n",
       "      <td>-9</td>\n",
       "      <td>-29</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>1.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-0.510826</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8248</th>\n",
       "      <td>397</td>\n",
       "      <td>1</td>\n",
       "      <td>0.913931</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.16</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>-12</td>\n",
       "      <td>5</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8249</th>\n",
       "      <td>545</td>\n",
       "      <td>-6</td>\n",
       "      <td>1.419068</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.14</td>\n",
       "      <td>1.2</td>\n",
       "      <td>-15</td>\n",
       "      <td>-15</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-0.356675</td>\n",
       "      <td>0.023</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8250 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      acc_rate  track         m     n  current_pitch  current_roll  \\\n",
       "0          -31     22  1.127497  0.03           1.44          -0.7   \n",
       "1          185    -40  1.363425 -0.10           0.30          -1.3   \n",
       "2          170    -17  0.794534  0.12           0.31           0.6   \n",
       "3         -399     -8  0.697676 -0.13           0.80          -0.7   \n",
       "4          -24    -18  1.127497  0.18           0.85          -1.8   \n",
       "...        ...    ...       ...   ...            ...           ...   \n",
       "8245        56    -40  0.886920 -0.21           0.39          -0.2   \n",
       "8246       199    -35  1.185305  0.01           0.32           1.5   \n",
       "8247       359     -3  0.852144  0.26           0.31           1.4   \n",
       "8248       397      1  0.913931  0.02           0.16          -1.1   \n",
       "8249       545     -6  1.419068  0.22           0.14           1.2   \n",
       "\n",
       "      absoluate_roll  climb_delta  roll_rate_delta  climb_delta_diff  ...  \\\n",
       "0                 -9            6            0.011              -0.9  ...   \n",
       "1                -12           16            0.022               0.1  ...   \n",
       "2                 -6            9           -0.006              -2.5  ...   \n",
       "3                 -7           15            0.008               0.1  ...   \n",
       "4                -18           -3            0.019              -0.2  ...   \n",
       "...              ...          ...              ...               ...  ...   \n",
       "8245              -6           32            0.012              -1.8  ...   \n",
       "8246              -5           -1           -0.009              -0.1  ...   \n",
       "8247              -9          -29           -0.014               1.2  ...   \n",
       "8248             -12            5            0.020               0.1  ...   \n",
       "8249             -15          -15           -0.005              -1.0  ...   \n",
       "\n",
       "      time8_delta  time9_delta  time10_delta  time11_delta  time12_delta  \\\n",
       "0             0.0          0.0           0.0         9.000           0.0   \n",
       "1             0.0          0.0           0.0         9.000           0.0   \n",
       "2             0.0          0.0           0.0         9.000           0.0   \n",
       "3             0.0          0.0           0.0         9.000           0.0   \n",
       "4             0.0          0.0           0.0         9.000           0.0   \n",
       "...           ...          ...           ...           ...           ...   \n",
       "8245          0.0          0.0           0.0         9.000           0.0   \n",
       "8246          0.0          0.0           0.0         9.000           0.0   \n",
       "8247          0.0          0.0           0.0         9.000           0.0   \n",
       "8248          0.0          0.0           0.0         9.002           0.0   \n",
       "8249          0.0          0.0           0.0         9.000           0.0   \n",
       "\n",
       "      time13_delta  time14_delta     omega    set  target  \n",
       "0            0.000         -10.0  0.336472  0.050     1.4  \n",
       "1            0.000         -10.0 -0.693147  0.016     0.5  \n",
       "2            0.001         -10.0 -0.916291  0.018     0.5  \n",
       "3            0.000         -10.0 -0.916291  0.015     0.2  \n",
       "4            0.000         -10.0 -0.223144  0.030     1.5  \n",
       "...            ...           ...       ...    ...     ...  \n",
       "8245         0.000         -10.0 -0.916291  0.015     0.4  \n",
       "8246         0.000         -10.0 -0.693147  0.017     0.6  \n",
       "8247         0.000         -10.0 -0.510826  0.024     0.8  \n",
       "8248         0.000         -10.0 -0.693147  0.018     0.9  \n",
       "8249         0.000         -10.0 -0.356675  0.023     1.5  \n",
       "\n",
       "[8250 rows x 41 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"C:\\\\CSE 517A\\\\milestone3\\\\train.csv\")\n",
    "da_test = pd.read_csv(\"C:\\\\CSE 517A\\\\milestone3\\\\test.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6897b387",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Here we split the data into features(x) and target(y)\n",
    "y_train = data.iloc[:,-1].tolist()\n",
    "x_train = data.iloc[:,:-1]\n",
    "x_train = pd.DataFrame(x_train)\n",
    "#x_train = pd.DataFrame(x_train, columns=feature.columns)\n",
    "x_test = da_test.iloc[:,1:41]\n",
    "#x_test = da_test\n",
    "x_test = pd.DataFrame(x_test)\n",
    "#x_test = pd.DataFrame(x_test, columns=feature.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6cac9307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_rate</th>\n",
       "      <th>track</th>\n",
       "      <th>m</th>\n",
       "      <th>n</th>\n",
       "      <th>current_pitch</th>\n",
       "      <th>current_roll</th>\n",
       "      <th>absoluate_roll</th>\n",
       "      <th>climb_delta</th>\n",
       "      <th>roll_rate_delta</th>\n",
       "      <th>climb_delta_diff</th>\n",
       "      <th>...</th>\n",
       "      <th>time7_delta</th>\n",
       "      <th>time8_delta</th>\n",
       "      <th>time9_delta</th>\n",
       "      <th>time10_delta</th>\n",
       "      <th>time11_delta</th>\n",
       "      <th>time12_delta</th>\n",
       "      <th>time13_delta</th>\n",
       "      <th>time14_delta</th>\n",
       "      <th>omega</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-103</td>\n",
       "      <td>-41</td>\n",
       "      <td>1.363425</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.14</td>\n",
       "      <td>1.8</td>\n",
       "      <td>-11</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-126</td>\n",
       "      <td>-22</td>\n",
       "      <td>0.718924</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-7</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-330</td>\n",
       "      <td>-6</td>\n",
       "      <td>1.390968</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-6</td>\n",
       "      <td>-14</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-0.510826</td>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-20</td>\n",
       "      <td>-16</td>\n",
       "      <td>1.072508</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-7</td>\n",
       "      <td>-4</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>259</td>\n",
       "      <td>-17</td>\n",
       "      <td>0.980199</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.45</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>-20</td>\n",
       "      <td>4</td>\n",
       "      <td>0.018</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-0.356675</td>\n",
       "      <td>0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5495</th>\n",
       "      <td>196</td>\n",
       "      <td>-45</td>\n",
       "      <td>0.941765</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>0.56</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>-7</td>\n",
       "      <td>15</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-0.223144</td>\n",
       "      <td>0.026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5496</th>\n",
       "      <td>-172</td>\n",
       "      <td>-34</td>\n",
       "      <td>1.061837</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.66</td>\n",
       "      <td>-2.3</td>\n",
       "      <td>-13</td>\n",
       "      <td>6</td>\n",
       "      <td>0.019</td>\n",
       "      <td>3.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>0.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5497</th>\n",
       "      <td>-307</td>\n",
       "      <td>-35</td>\n",
       "      <td>0.612626</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-10</td>\n",
       "      <td>-4</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5498</th>\n",
       "      <td>-394</td>\n",
       "      <td>-8</td>\n",
       "      <td>0.923116</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.91</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-11</td>\n",
       "      <td>-6</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-0.510826</td>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5499</th>\n",
       "      <td>-376</td>\n",
       "      <td>-3</td>\n",
       "      <td>0.990050</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.85</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-9</td>\n",
       "      <td>-6</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5500 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      acc_rate  track         m     n  current_pitch  current_roll  \\\n",
       "0         -103    -41  1.363425  0.06           1.14           1.8   \n",
       "1         -126    -22  0.718924  0.00           0.59           0.4   \n",
       "2         -330     -6  1.390968  0.13           0.87           0.5   \n",
       "3          -20    -16  1.072508  0.04           0.51           0.5   \n",
       "4          259    -17  0.980199  0.20           0.45          -1.3   \n",
       "...        ...    ...       ...   ...            ...           ...   \n",
       "5495       196    -45  0.941765 -0.15           0.56          -0.6   \n",
       "5496      -172    -34  1.061837 -0.05           0.66          -2.3   \n",
       "5497      -307    -35  0.612626  0.08           0.80           0.5   \n",
       "5498      -394     -8  0.923116  0.08           0.91           2.0   \n",
       "5499      -376     -3  0.990050  0.10           0.85          -0.2   \n",
       "\n",
       "      absoluate_roll  climb_delta  roll_rate_delta  climb_delta_diff  ...  \\\n",
       "0                -11            0           -0.011              -0.2  ...   \n",
       "1                 -7            1           -0.007               0.2  ...   \n",
       "2                 -6          -14           -0.003              -0.2  ...   \n",
       "3                 -7           -4           -0.004              -0.1  ...   \n",
       "4                -20            4            0.018              -0.1  ...   \n",
       "...              ...          ...              ...               ...  ...   \n",
       "5495              -7           15            0.006               0.0  ...   \n",
       "5496             -13            6            0.019               3.3  ...   \n",
       "5497             -10           -4           -0.010              -0.4  ...   \n",
       "5498             -11           -6           -0.011               0.2  ...   \n",
       "5499              -9           -6           -0.007              -1.1  ...   \n",
       "\n",
       "      time7_delta  time8_delta  time9_delta  time10_delta  time11_delta  \\\n",
       "0          0.0000          0.0        0.000           0.0           9.0   \n",
       "1         -0.0002          0.0        0.001           0.0           9.0   \n",
       "2         -0.0006          0.0       -0.002           0.0           9.0   \n",
       "3          0.0000          0.0        0.000           0.0           9.0   \n",
       "4          0.0000          0.0        0.000           0.0           9.0   \n",
       "...           ...          ...          ...           ...           ...   \n",
       "5495       0.0000          0.0        0.000           0.0           9.0   \n",
       "5496       0.0000          0.0        0.000           0.0           9.0   \n",
       "5497      -0.0004          0.0        0.000           0.0           9.0   \n",
       "5498       0.0000          0.0        0.000           0.0           9.0   \n",
       "5499       0.0000          0.0        0.000           0.0           9.0   \n",
       "\n",
       "      time12_delta  time13_delta  time14_delta     omega    set  \n",
       "0              0.0         0.002         -10.0  0.000000  0.036  \n",
       "1              0.0         0.000         -10.0 -0.693147  0.017  \n",
       "2              0.0         0.000         -10.0 -0.510826  0.020  \n",
       "3              0.0         0.000         -10.0 -0.693147  0.018  \n",
       "4              0.0         0.000         -10.0 -0.356675  0.027  \n",
       "...            ...           ...           ...       ...    ...  \n",
       "5495           0.0         0.000         -10.0 -0.223144  0.026  \n",
       "5496           0.0         0.000         -10.0 -0.693147  0.019  \n",
       "5497           0.0         0.000         -10.0 -0.693147  0.018  \n",
       "5498           0.0         0.000         -10.0 -0.510826  0.020  \n",
       "5499           0.0        -0.002         -10.0 -0.693147  0.018  \n",
       "\n",
       "[5500 rows x 40 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a37476",
   "metadata": {},
   "source": [
    "# Data preprocessing-Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "8a53bea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Here we choose standardd scaler here\n",
    "scaler = StandardScaler()\n",
    "## scale x only. Leave y unchanged\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a351c18",
   "metadata": {},
   "source": [
    "## 1. MLPRegressor\n",
    "### We tune the hyperparameters of MLPRegressor using Gridsearch and we find the best MLPRegressor model has relatively poor prediction results comparing to best Xgboost model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e98ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\50670\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\50670\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\50670\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\50670\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\50670\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\50670\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\50670\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\50670\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\50670\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\50670\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:619: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "C:\\Users\\50670\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:619: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "C:\\Users\\50670\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:619: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "C:\\Users\\50670\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:619: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "C:\\Users\\50670\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:619: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "C:\\Users\\50670\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:619: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "C:\\Users\\50670\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:619: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "C:\\Users\\50670\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:619: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "C:\\Users\\50670\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:619: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "C:\\Users\\50670\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:619: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "C:\\Users\\50670\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:619: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "C:\\Users\\50670\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:619: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "C:\\Users\\50670\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:619: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "C:\\Users\\50670\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:619: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "C:\\Users\\50670\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:619: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "C:\\Users\\50670\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:619: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "C:\\Users\\50670\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:619: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "C:\\Users\\50670\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:619: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "C:\\Users\\50670\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:619: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "C:\\Users\\50670\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:619: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    }
   ],
   "source": [
    "#Neural network\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "NN = MLPRegressor()\n",
    "param_grid_NN = {\n",
    "    #'max_iter': [100,200,500,1000], \n",
    "    'hidden_layer_sizes': [(30,30,30),(30,30,30,30),(30,30,30,30,30),(30,30,30,30,30,30), (50,50,50), (50,50,50,50),(50,50,50,50,50),(100,100,100),(100,100,100,100)],\n",
    "    'activation': [\"identity\", \"logistic\", \"tanh\", \"relu\"],\n",
    "    'solver': [\"adam\"], \n",
    "    'learning_rate' : [\"constant\", \"invscaling\", \"adaptive\"],\n",
    "    #'learning_rate_init':[0.001,0.0001,0.01]\n",
    "    \n",
    "}\n",
    "CV_NN = GridSearchCV(estimator=NN, scoring = 'neg_root_mean_squared_error', param_grid=param_grid_NN, cv= 10)\n",
    "CV_NN.fit(x_train, y_train)\n",
    "print(CV_NN.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "0dc20937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.16319117443370265\n"
     ]
    }
   ],
   "source": [
    "print(CV_NN.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "afb2d8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_best = MLPRegressor(activation = CV_NN.best_params_['activation'], solver = CV_NN.best_params_['solver'], learning_rate = CV_NN.best_params_['learning_rate'], hidden_layer_sizes = CV_NN.best_params_['hidden_layer_sizes']) \n",
    "NN_best.fit(x_train,y_train)\n",
    "y_pred = NN_best.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "b254ae7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "idd = []\n",
    "for i in range(1,5501):\n",
    "    idd.append(i)\n",
    "# processing data\n",
    "dataframe1 = pd.DataFrame({\n",
    "    'Id': idd, \n",
    "    'Target': y_pred})\n",
    "dataframe1.to_csv(\"C:\\\\CSE 517A\\\\milestone3\\\\pca_NN_test1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8980f5a",
   "metadata": {},
   "source": [
    "## 2. RandomForestRegressor\n",
    "### We tune the hyperparameters of RandomForestRegressor using Gridsearch and we find the best RandomForestRegressor model has relatively poor prediction results comparing to best Xgboost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "0b0924e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_features': 11, 'n_estimators': 500}\n"
     ]
    }
   ],
   "source": [
    "#RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "RF = RandomForestRegressor()\n",
    "param_grid_RF = {\n",
    "    #'max_iter': [100,200,500,1000], \n",
    "    'n_estimators': [10,20,30,50,100,200,500],\n",
    "    'max_features': [5,6,7,8,9,10,11,12], \n",
    "    #'learning_rate_init':[0.001,0.0001,0.01]\n",
    "    \n",
    "}\n",
    "CV_RF = GridSearchCV(estimator=RF, scoring = 'neg_root_mean_squared_error', param_grid=param_grid_RF, cv= 10)\n",
    "CV_RF.fit(x_train, y_train)\n",
    "print(CV_RF.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "4c06b934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.17128366591086913\n",
      "[1.4034 0.4572 0.5622 ... 0.6454 0.8808 0.6564]\n"
     ]
    }
   ],
   "source": [
    "print(CV_RF.best_score_)\n",
    "RF_best = RandomForestRegressor(max_features = CV_RF.best_params_['max_features'], n_estimators = CV_RF.best_params_['n_estimators']) \n",
    "RF_best.fit(x_train,y_train)\n",
    "y_pred = RF_best.predict(x_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "dfe5b2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "idd = []\n",
    "for i in range(1,5501):\n",
    "    idd.append(i)\n",
    "# processing data\n",
    "dataframe1 = pd.DataFrame({\n",
    "    'Id': idd, \n",
    "    'Target': y_pred})\n",
    "dataframe1.to_csv(\"C:\\\\CSE 517A\\\\milestone3\\\\test7.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271ef8ab",
   "metadata": {},
   "source": [
    "## 3. gradientboostingregressor\n",
    "### We tune the hyperparameters of gradientboostingRegressor using Gridsearch and we find the best gradientboostingRegressor model has relatively poor prediction results comparing to best Xgboost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "93f51659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'friedman_mse', 'learning_rate': 0.1, 'max_depth': 4, 'max_features': 9, 'n_estimators': 320}\n"
     ]
    }
   ],
   "source": [
    "#gradientboostingregressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "GBR = GradientBoostingRegressor()\n",
    "param_grid_GBR = {\n",
    "    'learning_rate': [0.1,0.01],\n",
    "    'n_estimators': [250,280,300,320,400],\n",
    "    'criterion' : ['friedman_mse'],\n",
    "    'max_depth': [4],\n",
    "    'max_features': [5,6,7,8,9,10],   \n",
    "    #'learning_rate_init':[0.001,0.0001,0.01]   \n",
    "}\n",
    "CV_GBR = GridSearchCV(estimator=GBR, scoring = 'neg_root_mean_squared_error', param_grid=param_grid_GBR, cv= 10)\n",
    "CV_GBR.fit(x_train, y_train)\n",
    "print(CV_GBR.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "656abcbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.15768908613187868\n",
      "[1.64719667 0.45122634 0.69763219 ... 0.61075027 0.91599124 0.64389532]\n"
     ]
    }
   ],
   "source": [
    "print(CV_GBR.best_score_)\n",
    "GBR_best = GradientBoostingRegressor(max_features = CV_GBR.best_params_['max_features'], n_estimators = CV_GBR.best_params_['n_estimators'], criterion = CV_GBR.best_params_['criterion'], max_depth = CV_GBR.best_params_['max_depth'], learning_rate = CV_GBR.best_params_['learning_rate']) \n",
    "GBR_best.fit(x_train,y_train)\n",
    "y_pred = GBR_best.predict(x_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9445cdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "idd = []\n",
    "for i in range(1,5501):\n",
    "    idd.append(i)\n",
    "# processing data\n",
    "dataframe1 = pd.DataFrame({\n",
    "    'Id': idd, \n",
    "    'Target': y_pred})\n",
    "dataframe1.to_csv(\"C:\\\\CSE 517A\\\\milestone3\\\\test_ensemble_6.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa42d588",
   "metadata": {},
   "source": [
    "## 4. xgboost(using f_classif to feature selection)\n",
    "### In this part, we drop some features in standardized dataset using the best results we get from the f_classif criterion feature selections, which we show in the part 6 in the codes, and fit the new dataset into the best xgboost model we get in xgb.ipynb, and we can see the RMSE of the model is 0.01818138492321396."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "65453229",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.81, 'eta': 0.1, 'gamma': 0, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 2261, 'nthread': 4, 'objective': 'reg:squarederror', 'scale_pos_weight': 1, 'seed': 42, 'subsample': 0.65}\n",
      "[1.5867591  0.38798904 0.6075203  ... 0.60691184 0.93658894 0.6598958 ]\n",
      "0.01818138492321396\n"
     ]
    }
   ],
   "source": [
    "#fclass best\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import f_classif\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "X_f = data.iloc[:, :-1]\n",
    "y_f = data['target']\n",
    "\n",
    "#apply SelectKBest class to extract top best features\n",
    "bestFeatures = SelectKBest(f_classif, k=36)\n",
    "bestFeaturesFit = bestFeatures.fit(X_f,y_f)\n",
    "dfscores = pd.DataFrame(bestFeaturesFit.scores_)  #Store predictor scores in a column \n",
    "dfcolumns = pd.DataFrame(X_f.columns)  #Store predictor variable names in a column\n",
    "\n",
    "# #concatenate scores with predictor names\n",
    "predScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "predScores.columns = ['Predictor','Score']   \n",
    "aaaa1 = predScores.nlargest(36,'Score')       \n",
    "aaaa = aaaa1['Predictor']\n",
    "aaaaa = aaaa.values\n",
    "x_train2 = data[aaaaa]\n",
    "x_test2 = da_test[aaaaa]\n",
    "#standardization\n",
    "scaler2 = StandardScaler()\n",
    "x_train2 = scaler1.fit_transform(x_train2)\n",
    "x_test2 = scaler1.transform(x_test2)\n",
    "\n",
    "XG = XGBRegressor()\n",
    "param_grid_XG = {\n",
    "    'eta': [0.1],\n",
    "    'n_estimators': [2261],\n",
    "    #'gamma': [0.5,0.05,0.005],\n",
    "    #'criterion' : ['friedman_mse'],\n",
    "    'max_depth': [5],\n",
    "    'min_child_weight':[1],\n",
    "    'gamma': [0],\n",
    "    'subsample': [0.65],\n",
    "    'colsample_bytree': [0.81],\n",
    "    'objective': ['reg:squarederror'],\n",
    "    'nthread': [4],\n",
    "    'scale_pos_weight': [1],\n",
    "    'seed': [42]\n",
    "    #'reg_alpha': [0,0.6,0.8,1,2,3,5],\n",
    "    #'reg_lambda': [0.2,0.5,0.8,1,2]\n",
    "    #'max_features': [5,6,7,8,9,10],   \n",
    "    #'learning_rate_init':[0.001,0.0001,0.01]   \n",
    "}\n",
    "CV_XG = GridSearchCV(estimator=XG, scoring = 'neg_root_mean_squared_error', param_grid=param_grid_XG, cv= 10)\n",
    "CV_XG.fit(x_train2, y_f)\n",
    "print(CV_XG.best_params_)\n",
    "XG_best = XGBRegressor(eta = CV_XG.best_params_['eta'], n_estimators = CV_XG.best_params_['n_estimators'], max_depth = CV_XG.best_params_['max_depth'], min_child_weight = CV_XG.best_params_['min_child_weight'], gamma = CV_XG.best_params_['gamma'], subsample = CV_XG.best_params_['subsample'], colsample_bytree = CV_XG.best_params_['colsample_bytree'],objective = CV_XG.best_params_['objective'],nthread = CV_XG.best_params_['nthread'], scale_pos_weight = CV_XG.best_params_['scale_pos_weight'], seed = CV_XG.best_params_['seed'] ) \n",
    "XG_best.fit(x_train2,y_f)\n",
    "y_pred2 = XG_best.predict(x_train2)\n",
    "RMSE = sqrt(mean_squared_error(y_f, y_pred2))\n",
    "print(y_pred2)\n",
    "print(RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "81da9b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.6463625  0.33600026 0.66345406 ... 0.6655925  0.9095385  0.66077304]\n"
     ]
    }
   ],
   "source": [
    "y_pred = XG_best.predict(x_test2)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "55778227",
   "metadata": {},
   "outputs": [],
   "source": [
    "idd = []\n",
    "for i in range(1,5501):\n",
    "    idd.append(i)\n",
    "# processing data\n",
    "dataframe1 = pd.DataFrame({\n",
    "    'Id': idd, \n",
    "    'Target': y_pred})\n",
    "dataframe1.to_csv(\"C:\\\\CSE 517A\\\\milestone3\\\\test_xgb_8.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a1fece",
   "metadata": {},
   "source": [
    "## 5. xgboost(using correlation coefficient to feature selection)\n",
    "### In this part, we drop some features in raw dataset using the best results we get from the correlation coefficient criterion feature selections, which we show in the part 6 in the codes, and fit the new dataset into the best xgboost model we get in xgb.ipynb, and we can see the RMSE of the model is 0.018728145968801596."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "8fc2612a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.81, 'eta': 0.1, 'gamma': 0, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 2261, 'nthread': 4, 'objective': 'reg:squarederror', 'scale_pos_weight': 1, 'seed': 42, 'subsample': 0.65}\n",
      "[1.3983419  0.52949464 0.49956667 ... 0.79657906 0.8768065  1.4936645 ]\n",
      "RMSE of the model:\n",
      " 0.018728145968801596\n"
     ]
    }
   ],
   "source": [
    "#correlation best\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import f_classif\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "data.corr()\n",
    "features_set = abs(data.corr()).sort_values(\"target\",ascending = False).index[1:41]\n",
    "x_train1 = data[features_set]\n",
    "data2 = da_test[features_set]\n",
    "y_train1 = data.iloc[:,-1]\n",
    "y_train1 = pd.DataFrame(y_train1, columns=[\"target\"])\n",
    "x_test1 = data2\n",
    "#scaler1 = StandardScaler()\n",
    "#x_train1 = scaler1.fit_transform(x_train1)\n",
    "#x_test1 = scaler1.transform(data2)\n",
    "\n",
    "XG = XGBRegressor()\n",
    "param_grid_XG = {\n",
    "    'eta': [0.1],\n",
    "    'n_estimators': [2261],\n",
    "    #'gamma': [0.5,0.05,0.005],\n",
    "    #'criterion' : ['friedman_mse'],\n",
    "    'max_depth': [5],\n",
    "    'min_child_weight':[1],\n",
    "    'gamma': [0],\n",
    "    'subsample': [0.65],\n",
    "    'colsample_bytree': [0.81],\n",
    "    'objective': ['reg:squarederror'],\n",
    "    'nthread': [4],\n",
    "    'scale_pos_weight': [1],\n",
    "    'seed': [42]\n",
    "    #'reg_alpha': [0,0.6,0.8,1,2,3,5],\n",
    "    #'reg_lambda': [0.2,0.5,0.8,1,2]\n",
    "    #'max_features': [5,6,7,8,9,10],   \n",
    "    #'learning_rate_init':[0.001,0.0001,0.01]   \n",
    "}\n",
    "CV_XG = GridSearchCV(estimator=XG, scoring = 'neg_root_mean_squared_error', param_grid=param_grid_XG, cv= 10)\n",
    "CV_XG.fit(x_train1, y_train1)\n",
    "print(CV_XG.best_params_)\n",
    "XG_best = XGBRegressor(eta = CV_XG.best_params_['eta'], n_estimators = CV_XG.best_params_['n_estimators'], max_depth = CV_XG.best_params_['max_depth'], min_child_weight = CV_XG.best_params_['min_child_weight'], gamma = CV_XG.best_params_['gamma'], subsample = CV_XG.best_params_['subsample'], colsample_bytree = CV_XG.best_params_['colsample_bytree'],objective = CV_XG.best_params_['objective'],nthread = CV_XG.best_params_['nthread'], scale_pos_weight = CV_XG.best_params_['scale_pos_weight'], seed = CV_XG.best_params_['seed'] ) \n",
    "XG_best.fit(x_train1,y_train1)\n",
    "y_pred2 = XG_best.predict(x_train1)\n",
    "RMSE = sqrt(mean_squared_error(y_train1, y_pred2))\n",
    "print(y_pred2)\n",
    "print('RMSE of the model:\\n',RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "9ab05def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.6781685  0.40454164 0.67163974 ... 0.64093375 0.9191177  0.62933385]\n"
     ]
    }
   ],
   "source": [
    "y_pred = XG_best.predict(x_test1)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "51c0a301",
   "metadata": {},
   "outputs": [],
   "source": [
    "idd = []\n",
    "for i in range(1,5501):\n",
    "    idd.append(i)\n",
    "# processing data\n",
    "dataframe1 = pd.DataFrame({\n",
    "    'Id': idd, \n",
    "    'Target': y_pred})\n",
    "dataframe1.to_csv(\"C:\\\\CSE 517A\\\\milestone3\\\\test_xgb_11.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58053adb",
   "metadata": {},
   "source": [
    "## 6. feature selection\n",
    "### Based on different feature selection criteria to generate new .csv dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "790916ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature selection\n",
    "#1. correlation\n",
    "for i in range(6,23,4):\n",
    "    data.corr()\n",
    "    features_set = abs(data.corr()).sort_values(\"target\",ascending = False).index[1:i]\n",
    "    data1 = data[features_set]\n",
    "    data2 = da_test[features_set]\n",
    "    y_train1 = data.iloc[:,-1]\n",
    "    y_train1 = pd.DataFrame(y_train1, columns=[\"target\"])\n",
    "    x_test1 = data2\n",
    "    new_data = pd.concat([data1, y_train1], axis=1)\n",
    "    new_data.to_csv(\"C:\\\\CSE 517A\\\\milestone3\\\\\" + str(i-1) + \"_features_train.csv\", index=False)\n",
    "    data2.to_csv(\"C:\\\\CSE 517A\\\\milestone3\\\\\" + str(i-1) + \"_features_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "0533d55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. f_classif\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "for i in range(5,22,4):\n",
    "    X_f = data.iloc[:, :-1]\n",
    "    y_f = data['target']\n",
    "\n",
    "    #apply SelectKBest class to extract top best features\n",
    "    bestFeatures = SelectKBest(f_classif, k=i)\n",
    "    bestFeaturesFit = bestFeatures.fit(X_f,y_f)\n",
    "    dfscores = pd.DataFrame(bestFeaturesFit.scores_)  #Store predictor scores in a column \n",
    "    dfcolumns = pd.DataFrame(X_f.columns)  #Store predictor variable names in a column\n",
    "\n",
    "    # #concatenate scores with predictor names\n",
    "    predScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "    predScores.columns = ['Predictor','Score']   \n",
    "    aaaa1 = predScores.nlargest(i,'Score')       \n",
    "    aaaa = aaaa1['Predictor']\n",
    "    aaaaa = aaaa.values\n",
    "    dat_tr = data[aaaaa]\n",
    "    dat_te = da_test[aaaaa]\n",
    "    new_data1 = pd.concat([dat_tr, y_f], axis=1)\n",
    "    new_data1.to_csv(\"C:\\\\CSE 517A\\\\milestone3\\\\\" + str(i) + \"_features_classf_train.csv\", index=False)\n",
    "    dat_te.to_csv(\"C:\\\\CSE 517A\\\\milestone3\\\\\" + str(i) + \"_features_classf_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "eb671967",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 PCA\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "from math import ceil\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.decomposition import PCA\n",
    "components_list = [5,10,15,20,25,30]\n",
    "for i in components_list:\n",
    "    X_pca = data.iloc[:, :-1]\n",
    "    y_pca = data['target']\n",
    "    Xte_pca = da_test.iloc[:,1:41]\n",
    "    pca = PCA(n_components = i)\n",
    "    pca_components = pca.fit_transform(X_pca)\n",
    "    pca_dataframe = pd.DataFrame(data = pca_components)\n",
    "    pca_df = pd.concat([pca_dataframe, y_pca], axis = 1)\n",
    "    xxxxxx = pca.transform(Xte_pca)\n",
    "    test_dataframe = pd.DataFrame(data = xxxxxx)\n",
    "    pca_df.to_csv(\"C:\\\\CSE 517A\\\\milestone3\\\\\" + str(i) + \"_features_pca_train.csv\", index=False)\n",
    "    test_dataframe.to_csv(\"C:\\\\CSE 517A\\\\milestone3\\\\\" + str(i) + \"_features_pca_test.csv\", index=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "a895c696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               0          1          2         3         4  target\n",
      "0      19.482484  32.505162 -13.950884 -1.469961 -0.984741     1.4\n",
      "1    -196.601662 -29.941641 -10.408250  0.588306  0.334559     0.5\n",
      "2    -181.559248  -5.941951  -8.299159 -5.205309 -2.254273     0.5\n",
      "3     387.428900   0.778300 -17.674613 -3.621680 -0.560545     0.2\n",
      "4      12.469928  -4.890303   3.098091  7.020724 -0.144404     1.5\n",
      "...          ...        ...        ...       ...       ...     ...\n",
      "8245  -67.649885 -33.344143 -26.424406 -5.349577 -1.891329     0.4\n",
      "8246 -210.538854 -21.448113   5.257065 -6.501659  0.284021     0.6\n",
      "8247 -370.424928  15.805378  26.542352 -2.241219  2.036164     0.8\n",
      "8248 -408.531275  12.753004  -7.461518  0.934719  0.713142     0.9\n",
      "8249 -556.477160  10.196718  14.033183  3.612034 -0.015328     1.5\n",
      "\n",
      "[8250 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "from math import ceil\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.decomposition import PCA\n",
    "components_list = [5,10,15,20,25,30]\n",
    "X_pca = data.iloc[:, :-1]\n",
    "y_pca = data['target']\n",
    "Xte_pca = da_test.iloc[:,1:41]\n",
    "pca = PCA(n_components = 5)\n",
    "pca_components = pca.fit_transform(X_pca)\n",
    "pca_dataframe = pd.DataFrame(data = pca_components)\n",
    "pca_df = pd.concat([pca_dataframe, y_pca], axis = 1)\n",
    "xxxxx = pca.transform(X_pca)\n",
    "xxxxxx = pca.transform(Xte_pca)\n",
    "print(pca_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05e7f5b",
   "metadata": {},
   "source": [
    "## 7. find best feature number based different criteria\n",
    "### 3 criteria we mention in the report: correlation coefficient, f_classif, PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "76b4ae33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Lowest RMSE we achieve by feature selection:\n",
      " 0.018271256814910333\n",
      "The number of features we choose:\n",
      " 31\n"
     ]
    }
   ],
   "source": [
    "#feature selection running 2\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "best_score = 10\n",
    "best_feat = 1\n",
    "for i in range(31,41,1):\n",
    "    data.corr()\n",
    "    features_set = abs(data.corr()).sort_values(\"target\",ascending = False).index[1:i]\n",
    "    x_train1 = data[features_set]\n",
    "    data2 = da_test[features_set]\n",
    "    y_train1 = data.iloc[:,-1]\n",
    "    y_train1 = pd.DataFrame(y_train1, columns=[\"target\"])\n",
    "    x_test1 = data2\n",
    "    #standardization\n",
    "    #scaler1 = StandardScaler()\n",
    "    #x_train1 = scaler1.fit_transform(x_train1)\n",
    "    #x_test1 = scaler1.transform(data2)\n",
    "    XG = XGBRegressor()\n",
    "    param_grid_XG = {\n",
    "    'eta': [0.1],\n",
    "    'n_estimators': [2261],\n",
    "    #'gamma': [0.5,0.05,0.005],\n",
    "    #'criterion' : ['friedman_mse'],\n",
    "    'max_depth': [5],\n",
    "    'min_child_weight':[1],\n",
    "    #'reg_alpha': [0,0.6,0.8,1,2,3,5],\n",
    "    #'reg_lambda': [0.2,0.5,0.8,1,2],\n",
    "    'gamma': [0],\n",
    "    'subsample': [0.65],\n",
    "    'colsample_bytree': [0.81],\n",
    "    'objective': ['reg:squarederror'],\n",
    "    'nthread': [4],\n",
    "    'scale_pos_weight': [1],\n",
    "    'seed': [42]\n",
    "    #'reg_alpha': [0,0.6,0.8,1,2,3,5],\n",
    "    #'reg_lambda': [0.2,0.5,0.8,1,2]\n",
    "    #'max_features': [5,6,7,8,9,10],   \n",
    "    #'learning_rate_init':[0.001,0.0001,0.01]   \n",
    "    }\n",
    "    CV_XG = GridSearchCV(estimator=XG, scoring = 'neg_root_mean_squared_error', param_grid=param_grid_XG, cv= 10)\n",
    "    CV_XG.fit(x_train1, y_train1)\n",
    "    XG_best = XGBRegressor(eta = CV_XG.best_params_['eta'], n_estimators = CV_XG.best_params_['n_estimators'], max_depth = CV_XG.best_params_['max_depth'], min_child_weight = CV_XG.best_params_['min_child_weight'], gamma = CV_XG.best_params_['gamma'], subsample = CV_XG.best_params_['subsample'], colsample_bytree = CV_XG.best_params_['colsample_bytree'],objective = CV_XG.best_params_['objective'],nthread = CV_XG.best_params_['nthread'], scale_pos_weight = CV_XG.best_params_['scale_pos_weight'], seed = CV_XG.best_params_['seed'] ) \n",
    "    XG_best.fit(x_train1,y_train1)\n",
    "    y_pred2 = XG_best.predict(x_train1)\n",
    "    if sqrt(mean_squared_error(y_train1, y_pred2)) < best_score:\n",
    "        best_score = sqrt(mean_squared_error(y_train1, y_pred2))\n",
    "        best_feat = i\n",
    "print('The Lowest RMSE we achieve by feature selection:\\n', best_score)\n",
    "print('The number of features we choose:\\n', best_feat)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "400db031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Lowest RMSE we achieve by feature selection:\n",
      " 0.018301262721484447\n",
      "The number of features we choose:\n",
      " 40\n"
     ]
    }
   ],
   "source": [
    "#flass_if running\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import f_classif\n",
    "best_score = 10\n",
    "best_feat = 1\n",
    "for i in range(31,41,1):\n",
    "    X_f = data.iloc[:, :-1]\n",
    "    y_f = data['target']\n",
    "\n",
    "    #apply SelectKBest class to extract top best features\n",
    "    bestFeatures = SelectKBest(f_classif, k=i)\n",
    "    bestFeaturesFit = bestFeatures.fit(X_f,y_f)\n",
    "    dfscores = pd.DataFrame(bestFeaturesFit.scores_)  #Store predictor scores in a column \n",
    "    dfcolumns = pd.DataFrame(X_f.columns)  #Store predictor variable names in a column\n",
    "\n",
    "    # #concatenate scores with predictor names\n",
    "    predScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "    predScores.columns = ['Predictor','Score']   \n",
    "    aaaa1 = predScores.nlargest(i,'Score')       \n",
    "    aaaa = aaaa1['Predictor']\n",
    "    aaaaa = aaaa.values\n",
    "    x_train2 = data[aaaaa]\n",
    "    x_test2 = da_test[aaaaa]\n",
    "    #standardization\n",
    "    #scaler2 = StandardScaler()\n",
    "    #x_train2 = scaler1.fit_transform(x_train2)\n",
    "    #x_test2 = scaler1.transform(x_test2)\n",
    "    XG = XGBRegressor()\n",
    "    param_grid_XG = {\n",
    "    'eta': [0.1],\n",
    "    'n_estimators': [2261],\n",
    "    #'gamma': [0.5,0.05,0.005],\n",
    "    #'criterion' : ['friedman_mse'],\n",
    "    'max_depth': [5],\n",
    "    'min_child_weight':[1],\n",
    "    #'reg_alpha': [0,0.6,0.8,1,2,3,5],\n",
    "    #'reg_lambda': [0.2,0.5,0.8,1,2],\n",
    "    'gamma': [0],\n",
    "    'subsample': [0.65],\n",
    "    'colsample_bytree': [0.81],\n",
    "    'objective': ['reg:squarederror'],\n",
    "    'nthread': [4],\n",
    "    'scale_pos_weight': [1],\n",
    "    'seed': [42]  \n",
    "    }\n",
    "    CV_XG = GridSearchCV(estimator=XG, scoring = 'neg_root_mean_squared_error', param_grid=param_grid_XG, cv= 10)\n",
    "    CV_XG.fit(x_train2, y_f)\n",
    "    XG_best = XGBRegressor(eta = CV_XG.best_params_['eta'], n_estimators = CV_XG.best_params_['n_estimators'], max_depth = CV_XG.best_params_['max_depth'], min_child_weight = CV_XG.best_params_['min_child_weight'], gamma = CV_XG.best_params_['gamma'], subsample = CV_XG.best_params_['subsample'], colsample_bytree = CV_XG.best_params_['colsample_bytree'],objective = CV_XG.best_params_['objective'],nthread = CV_XG.best_params_['nthread'], scale_pos_weight = CV_XG.best_params_['scale_pos_weight'], seed = CV_XG.best_params_['seed'] ) \n",
    "    XG_best.fit(x_train2,y_f)\n",
    "    y_pred3 = XG_best.predict(x_train2)\n",
    "    if sqrt(mean_squared_error(y_f, y_pred3)) < best_score:\n",
    "        best_score = sqrt(mean_squared_error(y_f, y_pred3))\n",
    "        best_feat = i\n",
    "print('The Lowest RMSE we achieve by feature selection:\\n', best_score)\n",
    "print('The number of features we choose:\\n', best_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b66ce90a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09912607429603613\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "#pca running\n",
    "#feature selection running\n",
    "from sklearn.decomposition import PCA\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "best_score = 10\n",
    "best_feat = 1\n",
    "#components_list = [5,10,15,20,25,30,35]\n",
    "for i in range(22,41,2):\n",
    "    X_pca = data.iloc[:, :-1]\n",
    "    y_pca = data['target']\n",
    "    Xte_pca = da_test.iloc[:,1:41]\n",
    "    pca = PCA(n_components = i)\n",
    "    pca_components = pca.fit_transform(X_pca)\n",
    "    pca_dataframe = pd.DataFrame(data = pca_components)\n",
    "    pca_df = pd.concat([pca_dataframe, y_pca], axis = 1)\n",
    "    xxxxxx = pca.transform(Xte_pca)\n",
    "    test_dataframe = pd.DataFrame(data = xxxxxx)\n",
    "    x_train3 = pca_df.iloc[:,:-1]\n",
    "    x_test3 = test_dataframe\n",
    "    #standardization\n",
    "    scaler3 = StandardScaler()\n",
    "    x_train3 = scaler1.fit_transform(x_train3)\n",
    "    x_test3 = scaler1.transform(x_test3)\n",
    "    XG = XGBRegressor()\n",
    "    param_grid_XG = {\n",
    "    'eta': [0.1],\n",
    "    'n_estimators': [200],\n",
    "    #'gamma': [0.5,0.05,0.005],\n",
    "    #'criterion' : ['friedman_mse'],\n",
    "    'max_depth': [5],\n",
    "    'min_child_weight':[1],\n",
    "    #'reg_alpha': [0,0.6,0.8,1,2,3,5],\n",
    "    #'reg_lambda': [0.2,0.5,0.8,1,2],\n",
    "    'gamma': [0],\n",
    "    'subsample': [0.65],\n",
    "    'colsample_bytree': [0.81],\n",
    "    'objective': ['reg:squarederror'],\n",
    "    'nthread': [4],\n",
    "    'scale_pos_weight': [1],\n",
    "    'seed': [42]  \n",
    "    }\n",
    "    CV_XG = GridSearchCV(estimator=XG, scoring = 'neg_root_mean_squared_error', param_grid=param_grid_XG, cv= 10)\n",
    "    CV_XG.fit(x_train3, y_pca)\n",
    "    XG_best = XGBRegressor(eta = CV_XG.best_params_['eta'], n_estimators = CV_XG.best_params_['n_estimators'], max_depth = CV_XG.best_params_['max_depth'], min_child_weight = CV_XG.best_params_['min_child_weight'], gamma = CV_XG.best_params_['gamma'], subsample = CV_XG.best_params_['subsample'], colsample_bytree = CV_XG.best_params_['colsample_bytree'],objective = CV_XG.best_params_['objective'],nthread = CV_XG.best_params_['nthread'], scale_pos_weight = CV_XG.best_params_['scale_pos_weight'], seed = CV_XG.best_params_['seed'] ) \n",
    "    XG_best.fit(x_train3,y_pca)\n",
    "    y_pred4 = XG_best.predict(x_train3)\n",
    "    if sqrt(mean_squared_error(y_pca, y_pred4)) < best_score:\n",
    "        best_score = sqrt(mean_squared_error(y_pca, y_pred4))\n",
    "        best_feat = i\n",
    "print('The Lowest RMSE we achieve by feature selection:\\n', best_score)\n",
    "print('The number of principal components we choose:\\n', best_feat)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
